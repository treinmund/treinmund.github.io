[
  {
    "objectID": "_pages/index.html",
    "href": "_pages/index.html",
    "title": "Tyler Reinmund",
    "section": "",
    "text": "My research begins from the premise that we, as people, have complex relationships with technology. We shape it; it shapes us. This relationship has both positive and negative effects for our societies and the environment. And for better or worse, those outcomes are experienced in different ways by different people. From this understanding, I study how we can direct the practice of technology development, and in turn its products, along socially desirable and environmentally aware paths. Currently, I am exploring these ideas in the design of data science systems.\n\n\nEducation\nDPhil in Computer Science, 2021 – Present\nUniversity of Oxford | Oxford, UK\nMSc in Science, Technology, & Society, 2020 – 2021\nUniversity College London | London, UK\nMaster of Business Administration, 2019 – 2020\nUniversity of Oxford | Oxford, UK\nBS in Biomedical Engineering, 2012 – 2016\nRensselaer Polytechnic Institute | Troy, US\n\nMy academic supervisors are Marina Jirotka and Lars Kunze, and my studies are co-funded by Newton Europe and the Oxford-Singapore Human-Machine Collaboration Programme, supported by a gift from Amazon Web Services."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Tyler Reinmund",
    "section": "",
    "text": "I am a doctoral researcher in the Human Centred Computing group at the University of Oxford.\nMy research begins from the premise that we, as people, have complex relationships with technology. We shape it; it shapes us. This relationship has both positive and negative effects for our societies and the environment. And for better or worse, those outcomes are experienced in different ways by different people.\nFrom this understanding, I study how we can direct the practice of technology development, and in turn its products, along socially desirable and environmentally aware paths. Currently, I am exploring these ideas in the design of machine learning systems.\n\n\n\nInterests\n\n\nHuman-centered data science\n\n\nHuman-AI interaction\n\n\nSociotechnical studies\n\n\n\n\nEducation\n\n\n\n\n\nDPhil in Computer Science, Expected 2024\n\n\nUniversity of Oxford\n\n\n\n\n\n\n\nMSc in Science, Technology, and Society, 2021\n\n\nUniversity College London\n\n\n\n\n\n\nMaster of Business Administration, 2020\n\n\nUniversity of Oxford\n\n\n\n\n\n\nB.S. in Biomedical Engineering, 2016\n\n\nRensselaer Polytechnic Institute"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About me",
    "section": "",
    "text": "Additionally, I lead the Responsible Technology Institute Student Network, an interdisciplinary and international student-led organisation that connects graduate students who share an interest in responsible innovation.\n\nResearch Interests\n\nHuman-centered data science\nHuman-AI interaction\nSociotechnical studies\n\n\n\nEducation\nDPhil in Computer Science, 2021 – Present\nUniversity of Oxford | Oxford, UK\nMSc in Science, Technology, & Society, 2020 – 2021\nUniversity College London | London, UK\nMaster of Business Administration, 2019 – 2020\nUniversity of Oxford | Oxford, UK\nBS in Biomedical Engineering, 2012 – 2016\nRensselaer Polytechnic Institute | Troy, US\n\n\nAcknowledgements\nMy academic supervisors are Marina Jirotka and Lars Kunze, and my studies are co-funded by Newton Europe and the Oxford-Singapore Human-Machine Collaboration Programme, supported by a gift from Amazon Web Services."
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "publications",
    "section": "",
    "text": "{%- for y in page.years %}\n\n{% bibliography -f papers -q @* [year={{y}}]* %} {% endfor %}"
  },
  {
    "objectID": "hai-bibliography.html",
    "href": "hai-bibliography.html",
    "title": "Machine Learning in Practice",
    "section": "",
    "text": "This paper reports on a contextual evaluation of a deep learning system used for diabetic retinopathy detection in health clinics in Thailand. The authors conduct pre- and post-deployment observations and interviews to understand the nurses workflow with and without the DL system, and evaluate the system’s performance as it is used in a clinical setting. The study points to the importance of contextual evaluations, as they can reveal social and environmental factors which impact model performance that would otherwise be abstracted from in a laboratory setting.\nThis paper reports on a field study with clinicians in rural China who use a AI clinical decision support system during diagnosis. Their results provide an empirical description of how the use of AI-CDSS in rural clinics is shaped by specific policy, institutional, and medical factors (e.g., there is high demand at rural clinics in China, health care policy limits what services smaller clinics can provide) and outline how clinicians perceive the use of the AI-CDSS.\n\n\nThe paper provides a useful venture into uncharted empirical territory, since most work to date has focused on North America and Europe. Also, their findings resonate with established themes in studies on information systems in health and social care (e.g., workflow integration, interoperability, professional autonomy). The authors offer a fairly light description of their methods, and they do not outline how long they spent at each clinic, whether there were any differences between clinics, and how those related to the observed challenges.\nThe authors report on design workshops to improve the interface design of an algorithmic tool used in child protection call screening in the US. They present 10 design concepts which fall broadly into four themes: engaging with discrepancies between human decisions and model predictions, facilitating interactive machine learning, visualising uncertainty, and providing feedback on decision making performance. After outlining the design concepts, the authors elicit feedback on them from 12 social workers in regards to perceived helpfulness, areas for improvement, and envisioned impact on decision making.\n\n\nOverall, the study leads to two main takeaways. First, the practices of some users may differ fundamentally from the assumptions built into machine learning. In this case, the social workers disagreed with the assumption that current cases can be compared to past, “similar” cases; their perspective holds that everyone is different and what matters when making a decision about someone’s case is their case, not anyone else’s. Second, the authors provide a use case for effective engagement with users in the design of ML-based software. The approach followed seems quite in-depth and engaging, based on observational studies, interviews, and design probes.\n\n\nThis study can be built upon by focusing on instances where the problem is not to re-design an existing interface, but rather to design an entirely new tool based on the needs of the users. It feels that they are trying to improve a “solution” that may not have been the right solution in the first place. Additionally, how could these efforts be extended beyond the interface? Similarly, this focus on the interface exclusively may have precluded them from considering changes that portray call screening as a collaborative practice; there seems to be the assumption that this work is done individually.\nThis paper reports on a series of participatory design workshops held with case workers, data scientists, and system developers that were involved in the development of an algorithmic decision-support system for job placement services in Denmark. The findings point to how the legitimacy of such tools is questioned by the anticipated enduser because of dissonances between how the enduser perceives their role and the role implied by the use of predictive tools, and how the applications of decision-support tools can be re-negotiated.\n\n\nThe methods of the paper are quite interesting, drawing from observational studies, interviews, and PD workshops; it allows them to gather a lot of interesting data from a range of participants. It would have been nice to see what decisions were ultimately settled on, and how power differences affected the discussions in the PD workshops. For example, did data scientists have more organisational power than the case workers? And how about the managers who ostensibly conceived of the decision support tool in the first place?\nA group of Google researchers evaluate the performance and acceptance of a content-based image retrieval system with interactive elements for use in pathology diagnoses. After engaging with three pathologists on their perspectives of CBIR systems, the researchers conduct a user study with a cohort of twelve pathologists, and ask them to evaluate the system in comparison to a traditional interface along measures of diagnostic utility, mental support for decision-making, workload, trust, future use, and overall preference.  One of most interesting finding that comes from this paper is that the use of refinement tools (i.e. interactive ML) enables system users to develop mental models of the ML algorithm, thereby increasing their willingness to use it.\nClinical decision support tools (DSTs) perform well in the lab, but often fail when implemented. Commonly cited reasons for this failure is that the design does not consider clinicians workflows and the collaborative nature of clinicians work. The study designs a clinical DST to support in the VAD implant decision process, and evaluate their design in three US hospitals. Their evaluation seeks to answer the questions: “(1) would clinicians naturally encounter the DST within their current workflow? (2) Would clinicians accept computational decision support in the public context of the meeting? (3) Does placing the prediction in the corner present the right amount of unremarkability?” (p. 4). The authors find that the recurrent multidisciplinary implant decision meeting is the time and place where clinicians are most likely to encounter a DST, and that there is not much resistance to its use in that setting. Physicians, surgeons, and mid-levels each saw a benefit in its use, and these tended to vary across their roles. But, there were a series of challenges offered by the VAD team during the evaluation. Clinicians were considered with the credibility of the model (its data source, whether its been validated in clinical trials, and where its been published), the ethics of using a prediction based on population-level statistics for individual patient decisions, and the static representation of the prediction.\n\nOverall, this is a great paper that includes significant detail on the concerns of physicians, potential incompatibilities between DSTs and their actual decision making processes, and factors researchers should consider when designing their own studies. But, I am left with the question of why did they choose VAD implants as the right place to intervene in. They do not mention that it is a particularly complicated decision, nor is it prone to significant human error. I get the sense that they are trying to squeeze ML into this area just for the sake of it."
  }
]